{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ef685e",
   "metadata": {},
   "source": [
    "#Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87201df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec6b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "file_path = \"climate_change_download_0.xls\"\n",
    "sheet_name = \"Data\"\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "859ae20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Copy to a new DataFrame to clean\n",
    "df_clean = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7732757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove rows with \"Text\" in 'SCALE' and 'Decimals' columns\n",
    "df_clean = df_clean[(df_clean['SCALE'] != 'Text') & (df_clean['Decimals'] != 'Text')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a9a29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Drop unnecessary columns\n",
    "df_clean = df_clean.drop(['Country name', 'Series code', 'SCALE', 'Decimals'], axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1990235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_11948\\2345497769.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean.replace([\"..\", \"\"], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Replace \"..\" and empty strings with NaN\n",
    "df_clean.replace([\"..\", \"\"], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea480a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove columns with only missing values\n",
    "df_clean.dropna(axis='columns', how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "237fcb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Remove rows with only missing values\n",
    "df_clean.dropna(axis='rows', how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dceaa36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country code</th>\n",
       "      <th>Series name</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>...</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>Land area below 5m (% of land area)</td>\n",
       "      <td>2.957481e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADO</td>\n",
       "      <td>Land area below 5m (% of land area)</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Land area below 5m (% of land area)</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Land area below 5m (% of land area)</td>\n",
       "      <td>2.082346e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Land area below 5m (% of land area)</td>\n",
       "      <td>4.967875e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>YEM</td>\n",
       "      <td>Urban population</td>\n",
       "      <td>2.497176e+06</td>\n",
       "      <td>2.693642e+06</td>\n",
       "      <td>2.909756e+06</td>\n",
       "      <td>3.139637e+06</td>\n",
       "      <td>3.373930e+06</td>\n",
       "      <td>3.605265e+06</td>\n",
       "      <td>3.817581e+06</td>\n",
       "      <td>4.024281e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.148619e+06</td>\n",
       "      <td>5.410331e+06</td>\n",
       "      <td>5.683412e+06</td>\n",
       "      <td>5.967458e+06</td>\n",
       "      <td>6.275723e+06</td>\n",
       "      <td>6.597265e+06</td>\n",
       "      <td>6.932789e+06</td>\n",
       "      <td>7.283068e+06</td>\n",
       "      <td>7.648699e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13508</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>Urban population</td>\n",
       "      <td>1.830400e+07</td>\n",
       "      <td>1.886488e+07</td>\n",
       "      <td>1.944609e+07</td>\n",
       "      <td>2.004848e+07</td>\n",
       "      <td>2.067294e+07</td>\n",
       "      <td>2.132040e+07</td>\n",
       "      <td>2.199214e+07</td>\n",
       "      <td>2.269759e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.634556e+07</td>\n",
       "      <td>2.690436e+07</td>\n",
       "      <td>2.744822e+07</td>\n",
       "      <td>2.798869e+07</td>\n",
       "      <td>2.853356e+07</td>\n",
       "      <td>2.907984e+07</td>\n",
       "      <td>2.963688e+07</td>\n",
       "      <td>3.019380e+07</td>\n",
       "      <td>3.084463e+07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13509</th>\n",
       "      <td>ZAR</td>\n",
       "      <td>Urban population</td>\n",
       "      <td>1.012093e+07</td>\n",
       "      <td>1.056945e+07</td>\n",
       "      <td>1.106005e+07</td>\n",
       "      <td>1.156863e+07</td>\n",
       "      <td>1.206149e+07</td>\n",
       "      <td>1.251513e+07</td>\n",
       "      <td>1.299062e+07</td>\n",
       "      <td>1.342856e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.612534e+07</td>\n",
       "      <td>1.686783e+07</td>\n",
       "      <td>1.764085e+07</td>\n",
       "      <td>1.843199e+07</td>\n",
       "      <td>1.933373e+07</td>\n",
       "      <td>2.026144e+07</td>\n",
       "      <td>2.121648e+07</td>\n",
       "      <td>2.220185e+07</td>\n",
       "      <td>2.321996e+07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13510</th>\n",
       "      <td>ZMB</td>\n",
       "      <td>Urban population</td>\n",
       "      <td>3.096861e+06</td>\n",
       "      <td>3.141668e+06</td>\n",
       "      <td>3.183257e+06</td>\n",
       "      <td>3.223515e+06</td>\n",
       "      <td>3.264940e+06</td>\n",
       "      <td>3.309118e+06</td>\n",
       "      <td>3.356932e+06</td>\n",
       "      <td>3.407476e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.729883e+06</td>\n",
       "      <td>3.819641e+06</td>\n",
       "      <td>3.912871e+06</td>\n",
       "      <td>4.011828e+06</td>\n",
       "      <td>4.128987e+06</td>\n",
       "      <td>4.253139e+06</td>\n",
       "      <td>4.384859e+06</td>\n",
       "      <td>4.524564e+06</td>\n",
       "      <td>4.614728e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13511</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Urban population</td>\n",
       "      <td>3.036069e+06</td>\n",
       "      <td>3.175023e+06</td>\n",
       "      <td>3.310512e+06</td>\n",
       "      <td>3.443082e+06</td>\n",
       "      <td>3.574012e+06</td>\n",
       "      <td>3.704048e+06</td>\n",
       "      <td>3.819482e+06</td>\n",
       "      <td>3.932953e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.367339e+06</td>\n",
       "      <td>4.422102e+06</td>\n",
       "      <td>4.469727e+06</td>\n",
       "      <td>4.512876e+06</td>\n",
       "      <td>4.558288e+06</td>\n",
       "      <td>4.600587e+06</td>\n",
       "      <td>4.649406e+06</td>\n",
       "      <td>4.717664e+06</td>\n",
       "      <td>4.814867e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10017 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country code                          Series name          1990  \\\n",
       "0              ABW  Land area below 5m (% of land area)  2.957481e+01   \n",
       "1              ADO  Land area below 5m (% of land area)  0.000000e+00   \n",
       "2              AFG  Land area below 5m (% of land area)  0.000000e+00   \n",
       "3              AGO  Land area below 5m (% of land area)  2.082346e-01   \n",
       "4              ALB  Land area below 5m (% of land area)  4.967875e+00   \n",
       "...            ...                                  ...           ...   \n",
       "13507          YEM                     Urban population  2.497176e+06   \n",
       "13508          ZAF                     Urban population  1.830400e+07   \n",
       "13509          ZAR                     Urban population  1.012093e+07   \n",
       "13510          ZMB                     Urban population  3.096861e+06   \n",
       "13511          ZWE                     Urban population  3.036069e+06   \n",
       "\n",
       "               1991          1992          1993          1994          1995  \\\n",
       "0               NaN           NaN           NaN           NaN           NaN   \n",
       "1               NaN           NaN           NaN           NaN           NaN   \n",
       "2               NaN           NaN           NaN           NaN           NaN   \n",
       "3               NaN           NaN           NaN           NaN           NaN   \n",
       "4               NaN           NaN           NaN           NaN           NaN   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "13507  2.693642e+06  2.909756e+06  3.139637e+06  3.373930e+06  3.605265e+06   \n",
       "13508  1.886488e+07  1.944609e+07  2.004848e+07  2.067294e+07  2.132040e+07   \n",
       "13509  1.056945e+07  1.106005e+07  1.156863e+07  1.206149e+07  1.251513e+07   \n",
       "13510  3.141668e+06  3.183257e+06  3.223515e+06  3.264940e+06  3.309118e+06   \n",
       "13511  3.175023e+06  3.310512e+06  3.443082e+06  3.574012e+06  3.704048e+06   \n",
       "\n",
       "               1996          1997  ...          2002          2003  \\\n",
       "0               NaN           NaN  ...           NaN           NaN   \n",
       "1               NaN           NaN  ...           NaN           NaN   \n",
       "2               NaN           NaN  ...           NaN           NaN   \n",
       "3               NaN           NaN  ...           NaN           NaN   \n",
       "4               NaN           NaN  ...           NaN           NaN   \n",
       "...             ...           ...  ...           ...           ...   \n",
       "13507  3.817581e+06  4.024281e+06  ...  5.148619e+06  5.410331e+06   \n",
       "13508  2.199214e+07  2.269759e+07  ...  2.634556e+07  2.690436e+07   \n",
       "13509  1.299062e+07  1.342856e+07  ...  1.612534e+07  1.686783e+07   \n",
       "13510  3.356932e+06  3.407476e+06  ...  3.729883e+06  3.819641e+06   \n",
       "13511  3.819482e+06  3.932953e+06  ...  4.367339e+06  4.422102e+06   \n",
       "\n",
       "               2004          2005          2006          2007          2008  \\\n",
       "0               NaN           NaN           NaN           NaN           NaN   \n",
       "1               NaN           NaN           NaN           NaN           NaN   \n",
       "2               NaN           NaN           NaN           NaN           NaN   \n",
       "3               NaN           NaN           NaN           NaN           NaN   \n",
       "4               NaN           NaN           NaN           NaN           NaN   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "13507  5.683412e+06  5.967458e+06  6.275723e+06  6.597265e+06  6.932789e+06   \n",
       "13508  2.744822e+07  2.798869e+07  2.853356e+07  2.907984e+07  2.963688e+07   \n",
       "13509  1.764085e+07  1.843199e+07  1.933373e+07  2.026144e+07  2.121648e+07   \n",
       "13510  3.912871e+06  4.011828e+06  4.128987e+06  4.253139e+06  4.384859e+06   \n",
       "13511  4.469727e+06  4.512876e+06  4.558288e+06  4.600587e+06  4.649406e+06   \n",
       "\n",
       "               2009          2010  2011  \n",
       "0               NaN           NaN   NaN  \n",
       "1               NaN           NaN   NaN  \n",
       "2               NaN           NaN   NaN  \n",
       "3               NaN           NaN   NaN  \n",
       "4               NaN           NaN   NaN  \n",
       "...             ...           ...   ...  \n",
       "13507  7.283068e+06  7.648699e+06   NaN  \n",
       "13508  3.019380e+07  3.084463e+07   NaN  \n",
       "13509  2.220185e+07  2.321996e+07   NaN  \n",
       "13510  4.524564e+06  4.614728e+06   NaN  \n",
       "13511  4.717664e+06  4.814867e+06   NaN  \n",
       "\n",
       "[10017 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29472fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_11948\\3009473549.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_clean = df_clean.applymap(lambda x: pd.to_numeric(x, errors='ignore'))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_11948\\3009473549.py:1: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df_clean = df_clean.applymap(lambda x: pd.to_numeric(x, errors='ignore'))\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_clean.applymap(lambda x: pd.to_numeric(x, errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "805fd32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country code     object\n",
       "Series name      object\n",
       "1990            float64\n",
       "1991            float64\n",
       "1992            float64\n",
       "1993            float64\n",
       "1994            float64\n",
       "1995            float64\n",
       "1996            float64\n",
       "1997            float64\n",
       "1998            float64\n",
       "1999            float64\n",
       "2000            float64\n",
       "2001            float64\n",
       "2002            float64\n",
       "2003            float64\n",
       "2004            float64\n",
       "2005            float64\n",
       "2006            float64\n",
       "2007            float64\n",
       "2008            float64\n",
       "2009            float64\n",
       "2010            float64\n",
       "2011            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65320cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shorter names corresponding to most relevant variables in a dictionary\n",
    "chosen_vars = {'Cereal yield (kg per hectare)': 'cereal_yield',\n",
    "               'Foreign direct investment, net inflows (% of GDP)': 'fdi_perc_gdp',\n",
    "               'Access to electricity (% of total population)': 'elec_access_perc',\n",
    "               'Energy use per units of GDP (kg oil eq./$1,000 of 2005 PPP $)': 'en_per_gdp',\n",
    "               'Energy use per capita (kilograms of oil equivalent)': 'en_per_cap',\n",
    "               'CO2 emissions, total (KtCO2)': 'co2_ttl',\n",
    "               'CO2 emissions per capita (metric tons)': 'co2_per_cap',\n",
    "               'CO2 emissions per units of GDP (kg/$1,000 of 2005 PPP $)': 'co2_per_gdp',\n",
    "               'Other GHG emissions, total (KtCO2e)': 'other_ghg_ttl',\n",
    "               'Methane (CH4) emissions, total (KtCO2e)': 'ch4_ttl',\n",
    "               'Nitrous oxide (N2O) emissions, total (KtCO2e)': 'n2o_ttl',\n",
    "               'Droughts, floods, extreme temps (% pop. avg. 1990-2009)': 'nat_emerg',\n",
    "               'Population in urban agglomerations >1million (%)': 'pop_urb_aggl_perc',\n",
    "               'Nationally terrestrial protected areas (% of total land area)': 'prot_area_perc',\n",
    "               'GDP ($)': 'gdp',\n",
    "               'GNI per capita (Atlas $)': 'gni_per_cap',\n",
    "               'Under-five mortality rate (per 1,000)': 'under_5_mort_rate',\n",
    "               'Population growth (annual %)': 'pop_growth_perc',\n",
    "               'Population': 'pop',\n",
    "               'Urban population growth (annual %)': 'urb_pop_growth_perc',\n",
    "               'Urban population': 'urb_pop'\n",
    "                }\n",
    "\n",
    "# rename all variables in the column \"Series name\" with comprehensible shorter versions\n",
    "df_clean['Series name'] = df_clean['Series name'].replace(to_replace=chosen_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "534b562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the short feature names into a list of strings\n",
    "chosen_cols = list(chosen_vars.values())\n",
    "\n",
    "# define an empty list, where sub-dataframes for each feature will be saved\n",
    "frame_list = []\n",
    "\n",
    "# iterate over all chosen features\n",
    "for variable in chosen_cols:\n",
    "\n",
    "    # pick only rows corresponding to the current feature\n",
    "    frame = df_clean[df_clean['Series name'] == variable]\n",
    "\n",
    "    # melt all the values for all years into one column and rename the columns correspondingly\n",
    "    frame = frame.melt(id_vars=['Country code', 'Series name']).rename(columns={'Country code': 'country', 'variable': 'year', 'value': variable}).drop(['Series name'], axis='columns')\n",
    "\n",
    "    # add the melted dataframe for the current feature into the list\n",
    "    frame_list.append(frame)\n",
    "\n",
    "\n",
    "# merge all sub-frames into a single dataframe, making an outer binding on the key columns 'country','year'\n",
    "from functools import reduce\n",
    "all_vars = reduce(lambda left, right: pd.merge(left, right, on=['country','year'], how='outer'), frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da46b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check the amount of missing values in each column\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country                   0\n",
       "year                      0\n",
       "cereal_yield           1377\n",
       "fdi_perc_gdp           1111\n",
       "elec_access_perc       5027\n",
       "en_per_gdp             2082\n",
       "en_per_cap             1956\n",
       "co2_ttl                1143\n",
       "co2_per_cap            1146\n",
       "co2_per_gdp            1557\n",
       "other_ghg_ttl          4542\n",
       "ch4_ttl                4526\n",
       "n2o_ttl                4526\n",
       "nat_emerg              4958\n",
       "pop_urb_aggl_perc      2582\n",
       "prot_area_perc          726\n",
       "gdp                     779\n",
       "gni_per_cap            1013\n",
       "under_5_mort_rate       716\n",
       "pop_growth_perc         278\n",
       "pop                     252\n",
       "urb_pop_growth_perc     490\n",
       "urb_pop                 467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"check the amount of missing values in each column\")\n",
    "all_vars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d837e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values by year:\n",
      "2005 : 1189\n",
      "2000 : 1273\n",
      "1995 : 1317\n",
      "1990 : 1427\n",
      "2007 : 1631\n",
      "2006 : 1633\n",
      "2004 : 1646\n",
      "2008 : 1708\n",
      "2003 : 1714\n",
      "2002 : 1715\n",
      "2001 : 1718\n",
      "1999 : 1729\n",
      "1998 : 1739\n",
      "1997 : 1746\n",
      "1996 : 1756\n",
      "1994 : 1781\n",
      "1993 : 1792\n",
      "1992 : 1810\n",
      "1991 : 1921\n",
      "2009 : 2078\n",
      "2010 : 3038\n",
      "2011 : 4893\n"
     ]
    }
   ],
   "source": [
    "all_vars_clean = all_vars\n",
    "\n",
    "#define an array with the unique year values\n",
    "years_count_missing = dict.fromkeys(all_vars_clean['year'].unique(), 0)\n",
    "for ind, row in all_vars_clean.iterrows():\n",
    "    years_count_missing[row['year']] += row.isnull().sum()\n",
    "\n",
    "# sort the years by missing values\n",
    "years_missing_sorted = dict(sorted(years_count_missing.items(), key=lambda item: item[1]))\n",
    "\n",
    "# print the missing values for each year\n",
    "print(\"missing values by year:\")\n",
    "for key, val in years_missing_sorted.items():\n",
    "    print(key, \":\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dc76d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing values in the whole dataset before filtering the years:\n",
      "41254\n",
      "number of rows before filtering the years:\n",
      "5126\n",
      "number of missing values in the whole dataset after filtering the years:\n",
      "29818\n",
      "number of rows after filtering the years:\n",
      "4194\n"
     ]
    }
   ],
   "source": [
    "print(\"number of missing values in the whole dataset before filtering the years:\")\n",
    "print(all_vars_clean.isnull().sum().sum())\n",
    "print(\"number of rows before filtering the years:\")\n",
    "print(all_vars_clean.shape[0])\n",
    "\n",
    "# filter only rows for years between 1991 and 2008 (having less missing values)\n",
    "all_vars_clean = all_vars_clean[(all_vars_clean['year'] >= 1991) & (all_vars_clean['year'] <= 2008)]\n",
    "\n",
    "print(\"number of missing values in the whole dataset after filtering the years:\")\n",
    "print(all_vars_clean.isnull().sum().sum())\n",
    "print(\"number of rows after filtering the years:\")\n",
    "print(all_vars_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "944f7033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values by country:\n",
      "AGO : 81\n",
      "ARG : 81\n",
      "AUS : 81\n",
      "AUT : 81\n",
      "BGD : 81\n",
      "BGR : 81\n",
      "BOL : 81\n",
      "BRA : 81\n",
      "CAN : 81\n",
      "CHE : 81\n",
      "CHL : 81\n",
      "CHN : 81\n",
      "CIV : 81\n",
      "CMR : 81\n",
      "COG : 81\n",
      "COL : 81\n",
      "CRI : 81\n",
      "DEU : 81\n",
      "DNK : 81\n",
      "DOM : 81\n",
      "ECU : 81\n",
      "EGY : 81\n",
      "EMU : 81\n",
      "ESP : 81\n",
      "FIN : 81\n",
      "FRA : 81\n",
      "GBR : 81\n",
      "GHA : 81\n",
      "GTM : 81\n",
      "HND : 81\n",
      "HUN : 81\n",
      "IDN : 81\n",
      "IND : 81\n",
      "IRL : 81\n",
      "ISR : 81\n",
      "ITA : 81\n",
      "JOR : 81\n",
      "JPN : 81\n",
      "KEN : 81\n",
      "KOR : 81\n",
      "LAC : 81\n",
      "LMC : 81\n",
      "LMY : 81\n",
      "MAR : 81\n",
      "MEX : 81\n",
      "MIC : 81\n",
      "MNA : 81\n",
      "MOZ : 81\n",
      "MYS : 81\n",
      "NGA : 81\n",
      "NLD : 81\n",
      "NZL : 81\n",
      "PAK : 81\n",
      "PAN : 81\n",
      "PER : 81\n",
      "PHL : 81\n",
      "PRT : 81\n",
      "PRY : 81\n",
      "ROM : 81\n",
      "SAS : 81\n",
      "SAU : 81\n",
      "SDN : 81\n",
      "SEN : 81\n",
      "SLV : 81\n",
      "SWE : 81\n",
      "SYR : 81\n",
      "TGO : 81\n",
      "THA : 81\n",
      "TUR : 81\n",
      "TZA : 81\n",
      "UMC : 81\n",
      "URY : 81\n",
      "USA : 81\n",
      "VEN : 81\n",
      "VNM : 81\n",
      "ZAF : 81\n",
      "ZMB : 81\n",
      "GRC : 82\n",
      "POL : 82\n",
      "YEM : 82\n",
      "ZAR : 82\n",
      "DZA : 84\n",
      "ETH : 84\n",
      "LIC : 84\n",
      "SSA : 84\n",
      "WLD : 84\n",
      "ARE : 85\n",
      "ECA : 85\n",
      "RUS : 86\n",
      "UKR : 86\n",
      "ARM : 87\n",
      "BLR : 87\n",
      "UZB : 87\n",
      "KAZ : 88\n",
      "CZE : 89\n",
      "IRN : 89\n",
      "BEL : 90\n",
      "AZE : 91\n",
      "GEO : 92\n",
      "LBN : 92\n",
      "HTI : 94\n",
      "NIC : 96\n",
      "BEN : 99\n",
      "BWA : 99\n",
      "CYP : 99\n",
      "GAB : 99\n",
      "HIC : 99\n",
      "JAM : 99\n",
      "KHM : 99\n",
      "LKA : 99\n",
      "MLT : 99\n",
      "MNG : 99\n",
      "NOR : 99\n",
      "OMN : 99\n",
      "SGP : 99\n",
      "TTO : 99\n",
      "TUN : 99\n",
      "ALB : 100\n",
      "EAP : 102\n",
      "NPL : 103\n",
      "EST : 104\n",
      "LVA : 104\n",
      "NAM : 104\n",
      "HRV : 105\n",
      "MDA : 105\n",
      "SVN : 105\n",
      "TJK : 105\n",
      "KGZ : 106\n",
      "LTU : 106\n",
      "MKD : 107\n",
      "SVK : 107\n",
      "TKM : 107\n",
      "LBY : 108\n",
      "LUX : 108\n",
      "BRN : 109\n",
      "KWT : 113\n",
      "BHR : 117\n",
      "CUB : 117\n",
      "ISL : 117\n",
      "ZWE : 117\n",
      "ERI : 121\n",
      "IRQ : 122\n",
      "BIH : 123\n",
      "HKG : 124\n",
      "BFA : 126\n",
      "GIN : 126\n",
      "MDG : 126\n",
      "MLI : 126\n",
      "NER : 126\n",
      "UGA : 126\n",
      "QAT : 135\n",
      "ATG : 136\n",
      "BHS : 136\n",
      "BLZ : 136\n",
      "BRB : 136\n",
      "COM : 136\n",
      "CPV : 136\n",
      "DMA : 136\n",
      "FJI : 136\n",
      "GNB : 136\n",
      "GRD : 136\n",
      "GUY : 136\n",
      "MUS : 136\n",
      "SWZ : 136\n",
      "VCT : 136\n",
      "VUT : 136\n",
      "DJI : 137\n",
      "SLB : 137\n",
      "SUR : 137\n",
      "GMB : 141\n",
      "BDI : 144\n",
      "CAF : 144\n",
      "LAO : 144\n",
      "MRT : 144\n",
      "MWI : 144\n",
      "PNG : 144\n",
      "RWA : 144\n",
      "SLE : 144\n",
      "TCD : 144\n",
      "BTN : 148\n",
      "LBR : 149\n",
      "SID : 152\n",
      "GNQ : 154\n",
      "KNA : 154\n",
      "LCA : 154\n",
      "SYC : 154\n",
      "TON : 154\n",
      "WSM : 154\n",
      "KIR : 156\n",
      "SRB : 158\n",
      "MDV : 164\n",
      "PLW : 166\n",
      "AFG : 170\n",
      "MMR : 171\n",
      "PRK : 171\n",
      "FSM : 184\n",
      "MHL : 184\n",
      "LSO : 190\n",
      "MAC : 198\n",
      "STP : 198\n",
      "TMP : 202\n",
      "NCL : 204\n",
      "ADO : 206\n",
      "SOM : 206\n",
      "WBG : 207\n",
      "GRL : 216\n",
      "ABW : 226\n",
      "BMU : 226\n",
      "PRI : 230\n",
      "MNE : 231\n",
      "PYF : 232\n",
      "LIE : 234\n",
      "MCO : 234\n",
      "CYM : 250\n",
      "FRO : 259\n",
      "GIB : 261\n",
      "COK : 270\n",
      "GUM : 270\n",
      "NIU : 270\n",
      "SMR : 270\n",
      "TUV : 272\n",
      "IMY : 282\n",
      "VIR : 285\n",
      "ASM : 288\n",
      "CHI : 288\n",
      "MNP : 288\n",
      "NRU : 288\n",
      "TCA : 296\n",
      "MYT : 324\n",
      "KSV : 325\n",
      "MAF : 342\n",
      "CUW : 357\n",
      "SXM : 357\n"
     ]
    }
   ],
   "source": [
    "# check the amount of missing values by country\n",
    "\n",
    "# define an array with the unique country values\n",
    "countries_count_missing = dict.fromkeys(all_vars_clean['country'].unique(), 0)\n",
    "\n",
    "# iterate through all rows and count the amount of NaN values for each country\n",
    "for ind, row in all_vars_clean.iterrows():\n",
    "    countries_count_missing[row['country']] += row.isnull().sum()\n",
    "\n",
    "# sort the countries by missing values\n",
    "countries_missing_sorted = dict(sorted(countries_count_missing.items(), key=lambda item: item[1]))\n",
    "\n",
    "# print the missing values for each country\n",
    "print(\"missing values by country:\")\n",
    "for key, val in countries_missing_sorted.items():\n",
    "    print(key, \":\", val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0cc6f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing values in the whole dataset before filtering the countries:\n",
      "29818\n",
      "number of rows before filtering the countries:\n",
      "4194\n",
      "number of missing values in the whole dataset after filtering the countries:\n",
      "7854\n",
      "number of rows after filtering the countries:\n",
      "1728\n"
     ]
    }
   ],
   "source": [
    "print(\"number of missing values in the whole dataset before filtering the countries:\")\n",
    "print(all_vars_clean.isnull().sum().sum())\n",
    "print(\"number of rows before filtering the countries:\")\n",
    "print(all_vars_clean.shape[0])\n",
    "\n",
    "\n",
    "# filter only rows for countries with less than 90 missing values\n",
    "countries_filter = []\n",
    "for key, val in countries_missing_sorted.items():\n",
    "    if val<90:\n",
    "        countries_filter.append(key)\n",
    "\n",
    "all_vars_clean = all_vars_clean[all_vars_clean['country'].isin(countries_filter)]\n",
    "\n",
    "print(\"number of missing values in the whole dataset after filtering the countries:\")\n",
    "print(all_vars_clean.isnull().sum().sum())\n",
    "print(\"number of rows after filtering the countries:\")\n",
    "print(all_vars_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd1c358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                   0\n",
       "year                      0\n",
       "cereal_yield             10\n",
       "fdi_perc_gdp             17\n",
       "elec_access_perc       1728\n",
       "en_per_gdp                0\n",
       "en_per_cap                0\n",
       "co2_ttl                   9\n",
       "co2_per_cap               9\n",
       "co2_per_gdp               9\n",
       "other_ghg_ttl          1446\n",
       "ch4_ttl                1440\n",
       "n2o_ttl                1440\n",
       "nat_emerg              1728\n",
       "pop_urb_aggl_perc         0\n",
       "prot_area_perc            0\n",
       "gdp                       2\n",
       "gni_per_cap              16\n",
       "under_5_mort_rate         0\n",
       "pop_growth_perc           0\n",
       "pop                       0\n",
       "urb_pop_growth_perc       0\n",
       "urb_pop                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vars_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89e4a97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values per column:\n",
      "country                 0\n",
      "year                    0\n",
      "cereal_yield           10\n",
      "fdi_perc_gdp           17\n",
      "en_per_gdp              0\n",
      "en_per_cap              0\n",
      "co2_ttl                 9\n",
      "co2_per_cap             9\n",
      "co2_per_gdp             9\n",
      "pop_urb_aggl_perc       0\n",
      "prot_area_perc          0\n",
      "gdp                     2\n",
      "gni_per_cap            16\n",
      "under_5_mort_rate       0\n",
      "pop_growth_perc         0\n",
      "pop                     0\n",
      "urb_pop_growth_perc     0\n",
      "urb_pop                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove features with more than 20 missing values\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "# create a boolean mapping of features with more than 20 missing values\n",
    "vars_bad = all_vars_clean.isnull().sum()>20\n",
    "\n",
    "# remove the columns corresponding to the mapping of the features with many missing values\n",
    "all_vars_clean2 = all_vars_clean.drop(compress(data = all_vars_clean.columns, selectors = vars_bad), axis='columns')\n",
    "\n",
    "print(\"Remaining missing values per column:\")\n",
    "print(all_vars_clean2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b17f1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values per column:\n",
      "country                0\n",
      "year                   0\n",
      "cereal_yield           0\n",
      "fdi_perc_gdp           0\n",
      "en_per_gdp             0\n",
      "en_per_cap             0\n",
      "co2_ttl                0\n",
      "co2_per_cap            0\n",
      "co2_per_gdp            0\n",
      "pop_urb_aggl_perc      0\n",
      "prot_area_perc         0\n",
      "gdp                    0\n",
      "gni_per_cap            0\n",
      "under_5_mort_rate      0\n",
      "pop_growth_perc        0\n",
      "pop                    0\n",
      "urb_pop_growth_perc    0\n",
      "urb_pop                0\n",
      "dtype: int64\n",
      "Final shape of the cleaned dataset:\n",
      "(1700, 18)\n"
     ]
    }
   ],
   "source": [
    "# delete rows with any number of missing values\n",
    "all_vars_clean3 = all_vars_clean2.dropna(axis='rows', how='any')\n",
    "\n",
    "print(\"Remaining missing values per column:\")\n",
    "print(all_vars_clean3.isnull().sum())\n",
    "\n",
    "print(\"Final shape of the cleaned dataset:\")\n",
    "print(all_vars_clean3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b8c5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the clean dataframe to a csv file\n",
    "all_vars_clean3.to_csv('data_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
